# Part I: 表格解决方法

这一部分会涉及几乎增强学习算法的所有核心理念。不过都是最简化的形式：状态与行动空间足够小，估计的价值函数可以通过数组或者表格来表示。这种情况，会有很多方法找到准确的解，也就是说可以找到最优的价值函数和最优的策略。不同于本书下一部分说的方法，下一部分的方法只能找到近似解，但是可以用来更加高效的解决规模大很多的问题。

这一部分第一章会讨论增强学习中一个特殊案例的解决方法，这一案例只有一个状态，被称作老虎机问题。第二章讨论问题的通用形式（有限马尔可夫决策过程），这一形式会贯穿本书后续所有内容，他的主要思想包括Bellman等式和价值函数。


后三章讨论的是解决有限马尔可夫决策问题的三类基本方法：动态规划、蒙特卡洛法、时间差分学习。每一类方法都有其优势与缺点。动态规划在数学上定义的比较完善，但是需要环境的完整、准确的模型。蒙特卡洛法不需要环境模型而且形式简单，但是不很适用于一步步的增量计算。时间差分方法不需要模型而且也是增量的，但是过于复杂难以分析。这些方法的还有其他的不同，包括他们的有效性和收敛速度。


最后的两章讨论这三种方法如何结合在一起来利用好他们各自最具有优势的特点。前一章内容是如何利用eligibility traces结合蒙特卡洛法和时间查分法的优点。最后一章介绍如何将时间差分学习方法和模型学习、规划方法（比如说动态规划）结合在一起提供一个表格增强学习问题的完备的、统一的解决方法。
